{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier (Logistic Regression)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This tutorial covers the implementation of a simple linear model using TensorFlow. After loading the so-called MNIST data-set with images of hand-written digits, we define and optimize a simple mathematical model in TensorFlow. The structure of the network is presented in the following figure.\n",
    "\n",
    "\n",
    "<img src=\"files/files/linear_classifier.png\">\n",
    "\n",
    "\n",
    "___Fig. 1-___ Sample Logistic Regression structure implemented for classifying MNIST digits \n",
    "\n",
    "You should be familiar with basic linear algebra, Machine Learning and classification. To specifically learn about the linear classifiers, read [this](https://cs231n.github.io/linear-classify/) article.\n",
    "\n",
    "## 0. Imports:\n",
    "We will start with importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the MNIST data\n",
    "\n",
    "For this tutorial we use the MNIST dataset. MNIST is a dataset of handwritten digits. If you are into machine learning, you might have heard of this dataset by now. MNIST is kind of benchmark of datasets for deep learning. One other reason that we use the MNIST is that it is easily accesible through Tensorflow.\n",
    "If you want to know more about the MNIST dataset you can check __Yann Lecun__'s [website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "### 1.1. Data dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = img_w = 28  # MNIST images are 28x28\n",
    "img_size_flat = img_h * img_w  # 28x28=784, the total number of pixels\n",
    "n_classes = 10  # Number of classes, one class per digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Helper functions to load the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mode='train'):\n",
    "    \"\"\"\n",
    "    Function to (download and) load the MNIST data\n",
    "    :param mode: train or test\n",
    "    :return: images and the corresponding labels\n",
    "    \"\"\"\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    if mode == 'train':\n",
    "        x_train, y_train, x_valid, y_valid = mnist.train.images, mnist.train.labels, \\\n",
    "                                             mnist.validation.images, mnist.validation.labels\n",
    "        return x_train, y_train, x_valid, y_valid\n",
    "    elif mode == 'test':\n",
    "        x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "    return x_test, y_test\n",
    "\n",
    "\n",
    "def randomize(x, y):\n",
    "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    shuffled_x = x[permutation, :]\n",
    "    shuffled_y = y[permutation]\n",
    "    return shuffled_x, shuffled_y\n",
    "\n",
    "\n",
    "def reformat(x, y):\n",
    "    \"\"\"\n",
    "    Reformats the data to the format acceptable for convolutional layers\n",
    "    :param x: input array\n",
    "    :param y: corresponding labels\n",
    "    :return: reshaped input and labels\n",
    "    \"\"\"\n",
    "    img_size, num_ch, num_class = int(np.sqrt(x.shape[-1])), 1, len(np.unique(np.argmax(y, 1)))\n",
    "    dataset = x.reshape((-1, img_size, img_size, num_ch)).astype(np.float32)\n",
    "    labels = (np.arange(num_class) == y[:, None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "\n",
    "def get_next_batch(x, y, start, end):\n",
    "    x_batch = x[start:end]\n",
    "    y_batch = y[start:end]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Load the data and display the sizes\n",
    "Now we can use the defined helper function in \"train\" mode which loads the train and validation images and their corresponding labels. We'll also display their sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "x_train, y_train, x_valid, y_valid = load_data(mode='train')\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(y_train)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "learning_rate = 0.001   # The optimization initial learning rate\n",
    "epochs = 2              # Total number of training epochs\n",
    "batch_size = 100        # Training batch size\n",
    "display_freq = 100      # Frequency of displaying the training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Network graph\n",
    "### 3.1. Placeholders for the inputs (x) and corresponding labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph for the linear model\n",
    "# Placeholders for inputs (x) and outputs(y)\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Build the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weight matrix initialized randomely from N~(0, 0.01)\n",
    "W = weight_variable(shape=[img_size_flat, n_classes])\n",
    "\n",
    "# create bias vector initialized as zero\n",
    "b = bias_variable(shape=[n_classes])\n",
    "\n",
    "output_logits = tf.matmul(x, W) + b\n",
    "y_pred = tf.nn.softmax(output_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Define the loss function, optimizer, accuracy, and predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions\n",
    "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')\n",
    "\n",
    "# Define the loss function, optimizer, and accuracy\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Initialize all variables and merge the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the op for initializing all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "global_step = 0\n",
    "# Number of training iterations in each epoch\n",
    "num_tr_iter = int(len(y_train) / batch_size)\n",
    "for epoch in range(epochs):\n",
    "print('Training epoch: {}'.format(epoch + 1))\n",
    "x_train, y_train = randomize(x_train, y_train)\n",
    "for iteration in range(num_tr_iter):\n",
    "    global_step += 1\n",
    "    start = iteration * batch_size\n",
    "    end = (iteration + 1) * batch_size\n",
    "    x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
    "\n",
    "    # Run optimization op (backprop)\n",
    "    feed_dict_batch = {x: x_batch, y: y_batch}\n",
    "    sess.run(optimizer, feed_dict=feed_dict_batch)\n",
    "\n",
    "    if iteration % display_freq == 0:\n",
    "        # Calculate and display the batch loss and accuracy\n",
    "        loss_batch, acc_batch = sess.run([loss, accuracy],\n",
    "                                         feed_dict=feed_dict_batch)\n",
    "\n",
    "        print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
    "              format(iteration, loss_batch, acc_batch))\n",
    "\n",
    "# Run validation after every epoch\n",
    "feed_dict_valid = {x: x_valid[:1000], y: y_valid[:1000]}\n",
    "loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
    "      format(epoch + 1, loss_valid, acc_valid))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Test the network after training\n",
    "# Accuracy\n",
    "x_test, y_test = load_data(mode='test')\n",
    "feed_dict_test = {x: x_test[:1000], y: y_test[:1000]}\n",
    "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
    "print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test\n",
    "### 5.1. Helper functions for plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, title=None):\n",
    "    \"\"\"\n",
    "    Create figure with 3x3 sub-plots.\n",
    "    :param images: array of images to be plotted, (9, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels (9,)\n",
    "    :param cls_pred: corresponding true labels (9,)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(28, 28), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            ax_title = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            ax_title = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_title(ax_title)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, size=20)\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_example_errors(images, cls_true, cls_pred, title=None):\n",
    "    \"\"\"\n",
    "    Function for plotting examples of images that have been mis-classified\n",
    "    :param images: array of all images, (#imgs, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels, (#imgs,)\n",
    "    :param cls_pred: corresponding predicted labels, (#imgs,)\n",
    "    \"\"\"\n",
    "    # Negate the boolean array.\n",
    "    incorrect = np.logical_not(np.equal(cls_pred, cls_true))\n",
    "\n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    incorrect_images = images[incorrect]\n",
    "\n",
    "    # Get the true and predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "    cls_true = cls_true[incorrect]\n",
    "\n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=incorrect_images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9],\n",
    "                title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Run the test and plot some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network after training\n",
    "# Accuracy\n",
    "x_test, y_test = load_data(mode='test')\n",
    "feed_dict_test = {x: x_test[:1000], y: y_test[:1000]}\n",
    "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Plot some of the correct and misclassified examples\n",
    "cls_pred = sess.run(cls_prediction, feed_dict=feed_dict_test)\n",
    "cls_true = np.argmax(y_test[:1000], axis=1)\n",
    "plot_images(x_test, cls_true, cls_pred, title='Correct Examples')\n",
    "plot_example_errors(x_test[:1000], cls_true, cls_pred, title='Misclassified Examples')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
