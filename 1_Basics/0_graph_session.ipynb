{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to learn Tensorflow is to understand its main key feature, the __\"computational graph\"__ approach. Basically, all Tensorflow codes contain two important parts:\n",
    "\n",
    "__Part 1:__ building the __GRAPH__ which represents the data flow of the computations\n",
    "\n",
    "__Part 2:__ running a __SESSION__ which executes the operations in the graph\n",
    "\n",
    "In fact, TensorFlow separates the definition of computations from their execution. These two parts are explained in more details in the following sections. Before that, remember that the first step is to import the Tensorflow library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives Python access to all of TensorFlow's classes, methods, and symbols. Using this command, TensorFlow library will be imported under the alias __tf__ so that later we can use it instead of typing the whole term __tensorflow__ each time.\n",
    "\n",
    "__What is a Tensor?__\n",
    "TensorFlow programs use a tensor data structure to represent all data. Tensor is a multi-dimensional array (0-D tensor: scalar, 1-D tensor: vector, 2-D tensor: matrix, and so on). So TensorFlow is simply referring to the flow of the Tensors in the Graph.\n",
    "<img src=\"files/files/graph.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPH\n",
    "The biggest idea of all of the big ideas about Tensorflow is that numeric computation is expressed as a computational graph. In other words, the backbone of any Tensorflow program is going to be a __Graph__. As mentioned on the TensorFlow website, \"A __computational graph__ (or graph in short) is a series of TensorFlow operations arranged into a graph of nodes\".\n",
    "\n",
    "So First let's see what does a node and operation mean?! The best way to explain it is by looking at a simple example. Suppose we want to write the code for function $f(x,y)=x^2y+y+2$. The Graph in TensorFlow will be something like:\n",
    "<img src=\"files/files/sample_graph.png\" width=\"500\" height=\"1000\" >\n",
    "\n",
    "As it can be seen, the graph is composed of a series of nodes connected to each other by edges. Each __node__ in the graph is called __op__ (short for operation). So we'll have one node for each operation; either for operations on tensors (like math operations) or generating tensors (like variables and constants). Each node takes zero or more tensors as inputs and produces a tensor as an output.\n",
    "\n",
    "Now Let's build a simple computational graph.\n",
    "\n",
    "\n",
    "### Example 1:\n",
    "\n",
    "Let's add two values, say a=2 and b=3, using TensorFlow. To do so, we need to call __tf.add()__. To see how it works and how many arguments it needs, simply Google it and check the first link (TensorFlow official documentation). The documentation says it can be used like __tf.add(x, y, name=None)__ where x and y are the values to be added together and __name__ is the operation name, i.e. the name associated to the addition node on the graph.\n",
    "\n",
    "If we call the operation __\"Add\"__, the code will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = 2\n",
    "b = 3\n",
    "c = tf.add(a, b, name='Add')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated graph and variables are:\n",
    "\n",
    "__*Note__: The graph is generated using __Tensorboard__ which is a visualization tool comes with TensorFlow. We'll learn more about it in the next tutorials.\n",
    "<img src=\"files/files/ex1.png\" width=\"800\" height=\"1500\">\n",
    "\n",
    "This code creates two input nodes (for inputs a=2 and b=3) and one output node for the addition operation (named Add). As you see, when we print out the variable __c__ (i.e. the output Tensor of the addition operation), it prints out the Tensor information; its name (Add), shape (__()__ means scalar), and type (32-bit integer). However, It does not spit out the result (2+3=5). Why?!\n",
    "\n",
    "To actually evaluate the nodes, we must run the computational graph within a __Session__. In simple words, the written code only generates the graph which only determines the expected sizes of Tensors and operations to be executed on them. However, it doesn't assign a numeric value to any of the Tensors. To assign these values and make them flow through the graph, we need to run a session.\n",
    "\n",
    "Therefore a TensorFlow Graph is something like a function definition in Python. It __WILL NOT__ do any computation for you (just like a function definition will not have any execution result). It __ONLY__ defines computation operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "To compute anything, a graph must be launched in a session. Technically speaking, session places the graph ops onto Devices, such as CPUs or GPUs, and provides methods to execute them. In our simple example, to run the graph and get the value for c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a Session object (assigned to __sess__), and then (the second line) invokes its run method to run enough of the computational graph to evaluate __c__. This means that it only runs that part of the graph which is necessary to get the value of __c__ (in this simple example, it runs the whole graph). The last line closes the session. \n",
    "\n",
    "The following code does the same thing and is more commonly used. The only difference is that there is no need to close the session at the end as it gets closed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the created graph one more time. Don't you see anything weird?\n",
    "<img src=\"files/files/ex1_2.png\" width=\"500\" height=\"1000\">\n",
    "Exactly! What is x and y?! We didn't define any x or y variable!\n",
    "\n",
    "Well... To explain the reason more clearly, let's make up two names; say __\"Python-name\"__ and __\"TensorFlow-name\"__. \n",
    "\n",
    "In an ideal Tensorflow case, __tf.add()__ receives two __Tensors__ with defined __\"TensorFlow-name\"__ as input (These names are separate from __Python-name__). For example, by writing $c = tf.add(a, b, name='Add')$, we're actually creating a variable (or Tensor) with __c__ as its Python-name and __Add__ as the TensorFlow-name. \n",
    "\n",
    "In the above code, we passed two Python variables (a=2 and b=3) which only have Python-names (a and b), but no TensorFlow-name. TensorFlow uses the TensorFlow-names for visualizing the graphs. Since a and b have no TensorFlow-name, it uses some default names, x and y. \n",
    "\n",
    "__*Note:__ This name mismatch can easily be solved by using tf.constant() for creating the input variables as Tensors instead of simply using Python variables (a=2, b=3). This is explained thoroughly in the next tutorial where we talk about TensorFlow DataTypes. \n",
    "\n",
    "For now, we'll continue using Python variables and change the Python variable names __a__ and __b__ into __x__ and __y__ to solve the name mismatch temporarily. \n",
    "\n",
    "Now let's look at a more complicated example.\n",
    "\n",
    "### Example 2:\n",
    "Creating a graph with multiple math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x, y, name='Add')\n",
    "mul_op = tf.multiply(x, y, name='Multiply')\n",
    "pow_op = tf.pow(add_op, mul_op, name='Power')\n",
    "useless_op = tf.multiply(x, add_op, name='Useless')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    pow_out, useless_out = sess.run([pow_op, useless_op])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created graph and the defined variables (Tensors and Python variables) will be like:\n",
    "<img src=\"files/files/ex2.png\" width=\"1000\" height=\"2000\">\n",
    "\n",
    "I called one of the operations useless_op because it's output is not used by other operations. Here I'm gonna explain a very __IMPORTANT__ point. Given this graph, if we fetch the __pow_op__ operation, it will first run the __add_op__ and __mul_op__ to get their output tensor and then run __pow_op__ on them to compute the required output value. In other words __useless_op__ will not be ran as it's output tensor is not used in running the __pow_op__ operation. \n",
    "\n",
    "__This is one of the advantages of defining a graph and running a session on it! It helps running only the required operations of the graph and skip the rest. This specially saves a significant amount of time for us when dealing with huge networks with hundreds and thousands of operations.__\n",
    "\n",
    "In the above code, as you can see in the defined session, we're fetching the value of two tensors (i.e. output tensors of __pow_op__ and __useless_op__) at the same time. This will run the whole graph to get the required output tensors.\n",
    "\n",
    "I hope this post have halped you understand the concept of __Graph__ and __Session__ in TensorFlow. Thanks for reading! If you have any question or doubt, feel free to leave a comment below. You can also send us feedback through the __contact us__ page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
