{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In the previous post, we read about the concepts of __Graph__ and __Session__ which describes the way the data flows in TensorFlow. In this tutorial, we'll take a look at some of the __Tensor Types__ used in TensorFlow and specially the ones commonly used in creating neural network models, namely ___Constant___, ___Variable___, and ___Placeholder___. \n",
    "\n",
    "This will also enable us to shed light on some of the points and questions left unanswered in the previous post.\n",
    "\n",
    "Remember that we need to import the TensorFlow library at the very beginning of our code using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 1. Constant \n",
    "\n",
    "As the name speaks for itself, __Constants__ are used as constant value tensors. They create a node that takes a constant value. You can simply create a constant tensor using __tf.constant__. It accepts the following arguments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a very simple example.\n",
    "\n",
    "### Example 1:\n",
    "Let's create two constants and add them together. Constant tensors can be defined simply by defining a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# create graph\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now Let's look at the created graph and generated data types:\n",
    "<img src=\"files/files/2_1.png\" width=\"1000\" height=\"2000\" >\n",
    "___Fig1. ___ __Left:__ generated graph visualized in Tensorboard, __Right:__ generated variables (screenshot captured from PyCharm debugger when running in debug mode)\n",
    "\n",
    "As it's depicted in the figure, we created 3 tensors with __\"Python-names\"__ _a_, _b_, and _c_. However, we didn't define any __\"TensorFlow-name\"__ for them. Therefore, TensorFlow assigns some default names to them which are depicted in the graph: __const__ and __const_1__ for the input constants and __add__ for the output of the addition operation. We can easily modify it and define our own names, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# create graph\n",
    "a = tf.constant(2, name='A')\n",
    "b = tf.constant(3, name='B')\n",
    "c = tf.add(a, b, name='Sum')\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the graph and created tensors are as follows:\n",
    "<img src=\"files/files/2_2.png\" width=\"1000\" height=\"2000\" >\n",
    "___Fig2. ___ generated graph (Left) and variables (Right) with the modified names\n",
    "\n",
    "\n",
    "We can also define constants of different types (integer, float, etc.) and shapes (vectors, matrices, etc.).\n",
    "\n",
    "\n",
    "### Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "s = tf.constant(2.3, name='scalar', dtype=tf.float32)\n",
    "m = tf.constant([[1, 2], [3, 4]], name='matrix')\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(s))\n",
    "    print(sess.run(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VARIABLE\n",
    "Variables are stateful nodes which output their current value; meaning that they can retain their value over multiple executions of a graph. They have a number of useful features such as:\n",
    "\n",
    "- They can be __saved__ to your disk during and after training. This allows people from different companies and groups to save, restore and send over their model parameters to other people.\n",
    "- By default, gradient updates (used in all neural networks) will apply to all variables in your graph. In fact, variables are the things that you want to tune in order to minimize the loss. \n",
    "\n",
    "These features make variables suitable to be used as the network parameters (i.e. weights and biases).\n",
    "\n",
    "You might ask what are the differences between variables and constants? Well there are two major differences:\n",
    "\n",
    "1. Constants are (guess what), constants. Their value doesn't change. You'd usually need your network parameters to be updated and that's where the __variable__ comes into play.\n",
    "\n",
    "2. Constants are stored in the graph definition which makes them memory-expensive. In other words, constants with millions of entries makes the graph loading much slower.\n",
    "\n",
    "\n",
    "Again, it's important to remember that creating a variables is an operation (look at the Fig. 2 of the first tutorial for a quick recap). When we evaluate these operations in the session, we'll get the output value of the operations.\n",
    "\n",
    "### 2.1. Create Variables\n",
    "To create a variable, you can use __tf.Variable__ as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable.\n",
    "w = tf.Variable(<initial-value>, name=<optional-name>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of creating scalar and matrix variables are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.Variable(2, name=\"scalar\") \n",
    "m = tf.Variable([[1, 2], [3, 4]], name=\"matrix\") \n",
    "W = tf.Variable(tf.zeros([784,10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable __W__ defined above will create a matrix with 784 rows and 10 columns which will be initialized by zeros. This can be used as a weight matrix of a feed-forward neural network (or even in a linear regression model) from a layer with 784 neuron to a layer with 10 neuron. We'll see more of this later in this turorial.\n",
    "\n",
    "__*Note:__ we use tf.Variable() with uppercase \"V\", and tf.constant with lowercase \"c\". You don't necessarily need to know the reason, but it's simply because tf.constant is an op, while tf.Variable is a class with multiple ops.\n",
    "\n",
    "__* IMPORTANT Note:__ Calling tf.Variable to create a variable is the old way of creating a variable. TensorFlow recommends to use the wraper __tf.get_variable__ which accepts the name, shape, etc as its arguments as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_variable(name,\n",
    "                shape=None,\n",
    "                dtype=None,\n",
    "                initializer=None,\n",
    "                regularizer=None,\n",
    "                trainable=True,\n",
    "                collections=None,\n",
    "                caching_device=None,\n",
    "                partitioner=None,\n",
    "                validate_shape=True,\n",
    "                use_resource=None,\n",
    "                custom_getter=None,\n",
    "                constraint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.get_variable(\"scalar\", initializer=tf.constant(2)) \n",
    "m = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\n",
    "W = tf.get_variable(\"weight_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Initialize Variables\n",
    "Variables need to be initialized. To do so, we have to invoke a __variable initializer operation__ and run the operation on the session.\n",
    "\n",
    "The following toy example shows how we can add an op to initialize the variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "a = tf.Variable(2)\n",
    "b = tf.Variable(3)\n",
    "c = a+b\n",
    "# add an Op to initialize global variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # run the variable initializer\n",
    "    sess.run(init_op)\n",
    "    # now we can run our operations\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Variables are usually used for weights and biases.\n",
    "\n",
    "__weights__ are usually initialized from a normal distribution using `tf.random_normal()` or `tf.truncated_normal()`.\n",
    "\n",
    "__biases__ are usually initialized from zeros using `tf.zeros()` or `tf.zeros_like()`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "weights = tf.Variable(tf.truncated_normal(shape=[2,3], stddev=0.01))\n",
    "biases = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "# add an Op to initialize global variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # run the variable initializer\n",
    "    sess.run(init_op)\n",
    "    # now we can run our operations\n",
    "    W, b = sess.run([weights, biases])\n",
    "    print('weights = ', W)\n",
    "    print('biases = ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might sometimes see that the variables are created with `tf.get_variable()` instead of `tf.Variable()`. The reason of using these two functions interchangebly relies on creating _name scopes_ and _variable scopes_. It is thoroughly explained in our [tensorboard tutorial]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "weights = tf.get_variable(name=\"W\", shape=[2,3], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "biases = tf.get_variable(name=\"b\", shape=[3], initializer=tf.zeros_initializer())\n",
    "\n",
    "# add an Op to initialize global variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # run the variable initializer\n",
    "    sess.run(init_op)\n",
    "    # now we can run our operations\n",
    "    W, b = sess.run([weights, biases])\n",
    "    print('weights = ', W)\n",
    "    print('biases = ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLACEHOLDER:\n",
    "Placeholders are tensors that are placed to hold the data.\n",
    "We can build our graph without needing the data (because data is huge).\n",
    "In the time of need, we can feed the data in the right place (guess what place ?!!)\n",
    "\n",
    "BUT, Placeholders are just holding the place... where should we feed the input?\n",
    "\n",
    "In a dictionaty called __feed_dict__.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "# create a placeholder of type float 32-bit, value is a vector of 3 elements\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "# create a constant of type float 32-bit, value is a vector of 3 elements\n",
    "b = tf.constant([5, 5, 5], tf.float32)\n",
    "c = a+b\n",
    "\n",
    "# launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # create a feed_dict:\n",
    "    feed_dict={a: [1, 2, 3]}\n",
    "    # feed it to placeholder a via the dict \n",
    "    print(sess.run(c, feed_dict=feed_dict)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Now let's see a cool example. We will load an image and slice a part of the image and visualize it.\n",
    "\n",
    "We will load an image and try to slice it using the _slice_ method in tensorflow. Complete the code to run the session.\n",
    "Complete the code and \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the image\n",
    "filename = 'flowers.jpg'\n",
    "raw_image_data = mpimg.imread(filename)\n",
    "\n",
    "# create a placeholder for the image\n",
    "image = tf.placeholder(dtype=\"uint8\", shape=[None, None, 3])\n",
    "# slice the image \n",
    "slice = tf.slice(image, begin=[1000, 0, 0], size=[200, 200, -1])\n",
    "\n",
    "# launch the graph in a session\n",
    "result = []\n",
    "with tf.Session() as session:\n",
    "    ######################## YOUR CODE HERE ##########################\n",
    "    # Hint: You should run the session and pass the op that you want # \n",
    "    # and the feed_dict and store the value in \"result\" variable.    #\n",
    "    #                                                                #\n",
    "    pass\n",
    "    #                                                                #\n",
    "    ##################################################################\n",
    "    \n",
    "plt.imshow(raw_image_data)\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(result)\n",
    "plt.title('Cropped image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
