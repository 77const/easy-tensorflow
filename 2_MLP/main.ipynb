{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "d_input = 784  # MNIST data input dimension (img shape: 28*28)\n",
    "h1 = 200  # number of units in hidden layer\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    name: weight name\n",
    "    shape: weight shape\n",
    "    \n",
    "    return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    name: bias variable name\n",
    "    shape: bias variable shape\n",
    "    \n",
    "    return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)\n",
    "\n",
    "\n",
    "def fc_layer(x, num_nodes, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Creates a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_nodes: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    \n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    in_dim = x.get_shape()[1]\n",
    "    W = weight_variable(name, shape=[in_dim, num_nodes])\n",
    "    b = bias_variable(name, [num_nodes])\n",
    "    layer = tf.matmul(x, W)\n",
    "    layer += b\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph\n",
    "# Placeholders for inputs (x), outputs(y)\n",
    "x = tf.placeholder(tf.float32, shape=[None, d_input], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')\n",
    "fc1 = fc_layer(x, h1, 'FC1', use_relu=True)\n",
    "output_logits = fc_layer(fc1, n_classes, 'OUT', use_relu=False)\n",
    "\n",
    "# Define loss, optimizer, accuracy for training\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# predict classes for testing and evluation\n",
    "predicted_classes = tf.argmax(output_logits, axis=1)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph (session)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    num_tr_iter = int(mnist.train.num_examples / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        print('Training epoch: {}'.format(epoch))\n",
    "        for iter in range(num_tr_iter):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Run optimization op (backprop)\n",
    "            _, loss_batch, acc = sess.run([optimizer, loss, accuracy],\n",
    "                                          feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "            if iter % display_step == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss_batch, acc_batch = sess.run([loss, accuracy],\n",
    "                                                 feed_dict={x: batch_x, y: batch_y})\n",
    "                print(\"iter {}:\\t Loss={:.2f},\\tTraining Accuracy={:.2f}\".\n",
    "                      format(iter, loss_batch, acc_batch))\n",
    "\n",
    "        # validation\n",
    "        loss_valid, acc_valid = sess.run([loss, accuracy],\n",
    "                                         feed_dict={x: mnist.validation.images,\n",
    "                                                    y: mnist.validation.labels})\n",
    "        print(\"Validation Accuracy:\",\n",
    "              sess.run(accuracy, feed_dict={x: mnist.validation.images,\n",
    "                                            y: mnist.validation.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the network\n",
    "# Calculate accuracy\n",
    "print(\"Testing Accuracy:\",\n",
    "      sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                    y: mnist.test.labels}))\n",
    "# Predict single images\n",
    "n_images = 4\n",
    "test_images = mnist.test.images[:n_images]\n",
    "preds = sess.run(predicted_classes, feed_dict={x: test_images})\n",
    "# Display\n",
    "fig = plt.figure()\n",
    "for i in range(n_images):\n",
    "    ax = fig.add_subplot(2, 2, i + 1)\n",
    "    ax.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    ax.set_title(\"Model prediction: {}\".format(preds[i]))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}