{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "learning_rate = 0.001  # The optimization learning rate\n",
    "epochs = 10  # Total number of training epochs\n",
    "batch_size = 100  # Training batch size\n",
    "display_freq = 100  # Frequency of displaying the training results\n",
    "\n",
    "# Network Parameters\n",
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_h = img_w = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_h * img_w\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "n_classes = 10\n",
    "\n",
    "# number of units in the first hidden layer\n",
    "h1 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(images, cls_true, cls_pred):\n",
    "    \"\"\"\n",
    "    Function for plotting examples of images that have been mis-classified\n",
    "    :param images: array of all images, (#imgs, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels, (#imgs,)\n",
    "    :param cls_pred: corresponding predicted labels, (#imgs,)\n",
    "    \"\"\"\n",
    "    # Negate the boolean array.\n",
    "    incorrect = np.logical_not(np.equal(cls_pred, cls_true))\n",
    "\n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    incorrect_images = images[incorrect]\n",
    "\n",
    "    # Get the true and predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "    cls_true = cls_true[incorrect]\n",
    "\n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=incorrect_images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])\n",
    "\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    \"\"\"\n",
    "    Create figure with 3x3 sub-plots.\n",
    "    :param images: array of images to be plotted, (9, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels (9,)\n",
    "    :param cls_pred: corresponding true labels (9,)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    img_h = img_w = np.sqrt(images.shape[-1]).astype(int)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape((img_h, img_w)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            title = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            title = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    name: weight name\n",
    "    shape: weight shape\n",
    "    \n",
    "    return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    name: bias variable name\n",
    "    shape: bias variable shape\n",
    "    \n",
    "    return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)\n",
    "\n",
    "\n",
    "def fc_layer(x, num_nodes, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Creates a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_nodes: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    \n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    in_dim = x.get_shape()[1]\n",
    "    W = weight_variable(name, shape=[in_dim, num_nodes])\n",
    "    b = bias_variable(name, [num_nodes])\n",
    "    layer = tf.matmul(x, W)\n",
    "    layer += b\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph\n",
    "# Placeholders for inputs (x), outputs(y)\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')\n",
    "fc1 = fc_layer(x, h1, 'FC1', use_relu=True)\n",
    "output_logits = fc_layer(fc1, n_classes, 'OUT', use_relu=False)\n",
    "\n",
    "# Define the loss function, optimizer, and accuracy\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "# Network predictions\n",
    "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 0\n",
      "iter 0:\t Loss=2.28,\tTraining Accuracy=0.74\n",
      "iter 100:\t Loss=0.34,\tTraining Accuracy=0.91\n",
      "iter 200:\t Loss=0.44,\tTraining Accuracy=0.84\n",
      "iter 300:\t Loss=0.23,\tTraining Accuracy=0.95\n",
      "iter 400:\t Loss=0.38,\tTraining Accuracy=0.93\n",
      "iter 500:\t Loss=0.34,\tTraining Accuracy=0.91\n",
      "Validation Accuracy: 0.9456\n",
      "Training epoch: 1\n",
      "iter 0:\t Loss=0.15,\tTraining Accuracy=0.96\n",
      "iter 100:\t Loss=0.25,\tTraining Accuracy=0.93\n",
      "iter 200:\t Loss=0.16,\tTraining Accuracy=0.96\n",
      "iter 300:\t Loss=0.16,\tTraining Accuracy=0.94\n",
      "iter 400:\t Loss=0.15,\tTraining Accuracy=0.95\n",
      "iter 500:\t Loss=0.13,\tTraining Accuracy=0.97\n",
      "Validation Accuracy: 0.9622\n",
      "Training epoch: 2\n",
      "iter 0:\t Loss=0.14,\tTraining Accuracy=0.97\n",
      "iter 100:\t Loss=0.06,\tTraining Accuracy=1.00\n",
      "iter 200:\t Loss=0.11,\tTraining Accuracy=0.97\n",
      "iter 300:\t Loss=0.08,\tTraining Accuracy=0.99\n",
      "iter 400:\t Loss=0.09,\tTraining Accuracy=0.97\n",
      "iter 500:\t Loss=0.07,\tTraining Accuracy=0.98\n",
      "Validation Accuracy: 0.9674\n",
      "Training epoch: 3\n",
      "iter 0:\t Loss=0.09,\tTraining Accuracy=0.97\n",
      "iter 100:\t Loss=0.12,\tTraining Accuracy=0.96\n",
      "iter 200:\t Loss=0.08,\tTraining Accuracy=0.97\n",
      "iter 300:\t Loss=0.11,\tTraining Accuracy=0.96\n",
      "iter 400:\t Loss=0.15,\tTraining Accuracy=0.95\n",
      "iter 500:\t Loss=0.03,\tTraining Accuracy=1.00\n",
      "Validation Accuracy: 0.9732\n",
      "Training epoch: 4\n",
      "iter 0:\t Loss=0.05,\tTraining Accuracy=0.99\n",
      "iter 100:\t Loss=0.03,\tTraining Accuracy=0.99\n",
      "iter 200:\t Loss=0.09,\tTraining Accuracy=0.97\n",
      "iter 300:\t Loss=0.07,\tTraining Accuracy=0.98\n",
      "iter 400:\t Loss=0.11,\tTraining Accuracy=0.95\n",
      "iter 500:\t Loss=0.03,\tTraining Accuracy=1.00\n",
      "Validation Accuracy: 0.9754\n",
      "Training epoch: 5\n",
      "iter 0:\t Loss=0.04,\tTraining Accuracy=0.99\n",
      "iter 100:\t Loss=0.02,\tTraining Accuracy=0.99\n",
      "iter 200:\t Loss=0.03,\tTraining Accuracy=1.00\n",
      "iter 300:\t Loss=0.05,\tTraining Accuracy=0.98\n",
      "iter 400:\t Loss=0.04,\tTraining Accuracy=0.98\n",
      "iter 500:\t Loss=0.06,\tTraining Accuracy=0.98\n",
      "Validation Accuracy: 0.9788\n",
      "Training epoch: 6\n",
      "iter 0:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 100:\t Loss=0.03,\tTraining Accuracy=0.98\n",
      "iter 200:\t Loss=0.04,\tTraining Accuracy=0.99\n",
      "iter 300:\t Loss=0.02,\tTraining Accuracy=1.00\n",
      "iter 400:\t Loss=0.12,\tTraining Accuracy=0.97\n",
      "iter 500:\t Loss=0.08,\tTraining Accuracy=0.99\n",
      "Validation Accuracy: 0.9788\n",
      "Training epoch: 7\n",
      "iter 0:\t Loss=0.06,\tTraining Accuracy=0.98\n",
      "iter 100:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 200:\t Loss=0.09,\tTraining Accuracy=0.98\n",
      "iter 300:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 400:\t Loss=0.04,\tTraining Accuracy=0.99\n",
      "iter 500:\t Loss=0.04,\tTraining Accuracy=1.00\n",
      "Validation Accuracy: 0.98\n",
      "Training epoch: 8\n",
      "iter 0:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 100:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 200:\t Loss=0.02,\tTraining Accuracy=1.00\n",
      "iter 300:\t Loss=0.02,\tTraining Accuracy=1.00\n",
      "iter 400:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 500:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "Validation Accuracy: 0.9788\n",
      "Training epoch: 9\n",
      "iter 0:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 100:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "iter 200:\t Loss=0.00,\tTraining Accuracy=1.00\n",
      "iter 300:\t Loss=0.03,\tTraining Accuracy=0.99\n",
      "iter 400:\t Loss=0.02,\tTraining Accuracy=1.00\n",
      "iter 500:\t Loss=0.01,\tTraining Accuracy=1.00\n",
      "Validation Accuracy: 0.9802\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph (session)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "num_tr_iter = int(mnist.train.num_examples / batch_size)\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch))\n",
    "    for iter in range(num_tr_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        _, loss_batch, acc = sess.run([optimizer, loss, accuracy],\n",
    "                                      feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if iter % display_freq == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
    "                                             feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"iter {}:\\t Loss={:.2f},\\tTraining Accuracy={:.2f}\".\n",
    "                  format(iter, loss_batch, acc_batch))\n",
    "\n",
    "    # validation\n",
    "    loss_valid, acc_valid = sess.run([loss, accuracy],\n",
    "                                     feed_dict={x: mnist.validation.images,\n",
    "                                                y: mnist.validation.labels})\n",
    "    print(\"Validation Accuracy:\",\n",
    "          sess.run(accuracy, feed_dict={x: mnist.validation.images,\n",
    "                                        y: mnist.validation.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEICAYAAADFrJaoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlaNMV9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c75ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the network\n",
    "# Calculate accuracy\n",
    "print(\"Testing Accuracy:\",\n",
    "      sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                    y: mnist.test.labels}))\n",
    "# Predict single images\n",
    "n_images = 4\n",
    "test_images = mnist.test.images[:n_images]\n",
    "preds = sess.run(cls_prediction, feed_dict={x: test_images})\n",
    "# Display\n",
    "fig = plt.figure()\n",
    "for i in range(n_images):\n",
    "    ax = fig.add_subplot(2, 2, i + 1)\n",
    "    ax.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    ax.set_title(\"Model prediction: {}\".format(preds[i]))\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
