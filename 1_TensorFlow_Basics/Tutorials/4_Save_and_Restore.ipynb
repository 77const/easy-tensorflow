{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Restore\n",
    "In this post we are going to talk about how to save the parameters into the disk and restore the saved parameters from the disk. The savable/restorable paramters of the network are __Variables__ (i.e. weights and biases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLDR: \n",
    "\n",
    "To save and restore your variables, all you need to do is to call the `tf.train.Saver()` at the end of you graph.\n",
    "\n",
    "```\n",
    "# create the graph\n",
    "X = tf.placeholder(..)\n",
    "Y = tf.placeholder(..)\n",
    "w = tf.get_variale(..)\n",
    "b = tf.get_variale(..)\n",
    "...\n",
    "loss = tf.losses.mean_squared_error(..)\n",
    "optimizer = tf.train.AdamOptimizer(..).minimize(loss)\n",
    "...\n",
    "\n",
    "saver = tf.tfain.Saver()\n",
    "```\n",
    "\n",
    "__In the train mode__, in the session we will initialize the variables and run our network. At the end of training, we will save the variables using `saver.save()`:\n",
    "\n",
    "```python\n",
    "# TRAIN\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.globale_variables_initializer())\n",
    "    # train our model\n",
    "    for step in range(steps):\n",
    "        sess.run(optimizer)\n",
    "        ...\n",
    "    saved_path = saver.save(sess, './my-model', global_step=step)\n",
    "```\n",
    "\n",
    "This will create 3 files (`data`, `index`, `meta`) with a suffix of the step you saved your model.\n",
    "\n",
    "__In the test mode__, in the session we will restore the variables using `saver.restore()` and validate or test our model.\n",
    "\n",
    "```python\n",
    "# TEST\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './my-model')\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Save and Restore Two Variables:\n",
    "### 1.1 Save:\n",
    "We will start with saving and restoring two variables in TensorFlow. We will create a graph with two variables. Let's create two variables `a = [3 3]` and `b = [5 5 5]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# create variables a and b\n",
    "a = tf.get_variable(\"A\", initializer=tf.constant(3, shape=[2]))\n",
    "b = tf.get_variable(\"B\", initializer=tf.constant(5, shape=[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the __lower__case letter as python name and __UPPER__case letter as TensorFlow name. It will be important when we want to import the graph in restoring the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recall from 2_Tensor_Types:__ Variables need to be initialized before being used. To do so, we have to invoke a __variable initializer operation__ and run the operation on the session. This is the easiest way to initialize variables which initializes all variables at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize all of the variables\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, on the session, we can initialize the variables and run the to see the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  [3 3]\n",
      "b =  [5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# run the session\n",
    "with tf.Session() as sess:\n",
    "    # initialize all of the variables in the session\n",
    "    sess.run(init_op)\n",
    "    # run the session to get the value of the variable\n",
    "    a_out, b_out = sess.run([a, b])\n",
    "    print('a = ', a_out)\n",
    "    print('b = ', b_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important Note:__ All of the variables exist in the scope of the session. So, after the session is closed, we will loose the variable. \n",
    "\n",
    "In order to save the variable, we will call the saver function using `tf.train.Saver()` in our graph. This function will find all the variables in the graph. We can see the list of all variables in `_var_list`. Let's create a `saver` object and take a look at the `_var_list` in the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var 0: <tf.Variable 'A:0' shape=(2,) dtype=int32_ref>\n",
      "Var 1: <tf.Variable 'B:0' shape=(3,) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "# create saver object\n",
    "saver = tf.train.Saver()\n",
    "for i, var in enumerate(saver._var_list):\n",
    "    print('Var {}: {}'.format(i, var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our graph consists of two variables that listed above.\n",
    "\n",
    "__Important Note__: Notice the `:0` at the end of the variable name. For more about tensor naming check [here](https://stackoverflow.com/questions/36150834/how-does-tensorflow-name-tensors).\n",
    "\n",
    "Now that the saver object is created in the graph, in the session, we can call the `saver.save()` function to save the variables in the disk. We have to pass the created session (`sess`) and the path to the file that we want to save the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in ./saved_variable\n"
     ]
    }
   ],
   "source": [
    "# run the session\n",
    "with tf.Session() as sess:\n",
    "    # initialize all of the variables in the session\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # save the variable in the disk\n",
    "    saved_path = saver.save(sess, './saved_variable')\n",
    "    print('model saved in {}'.format(saved_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check your working directory, you will notice that 3  new files have been created with the name `saved_variable` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_variable.data-00000-of-00001\n",
      "saved_variable.meta\n",
      "saved_variable.index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for file in os.listdir('.'):\n",
    "    if 'saved_variable' in file:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__.data:__ Contains variable values\n",
    "\n",
    "__.meta:__ Contains graph structure\n",
    "\n",
    "__.index:__ Identifies checkpoints (we will explain it in section 2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Restore:\n",
    "Now that all the things that you need is saved in the disk, you can load your saved variables in the session using `saver.restore()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_variable\n",
      "a =  [3 3]\n",
      "b =  [5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# run the session\n",
    "with tf.Session() as sess:\n",
    "    # restore the saved vairable\n",
    "    saver.restore(sess, './saved_variable')\n",
    "    # print the loaded variable\n",
    "    a_out, b_out = sess.run([a, b])\n",
    "    print('a = ', a_out)\n",
    "    print('b = ', b_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this time we did not initialize the variables in our session. Instead, we restored them from the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important Note:__ In order to restore the parameters, the graph should be defined. Since we defined the graph in top, we didn't have a problem restoring the parameters. But what happens if we have not loaded the graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_variable\n",
      "The Session graph is empty.  Add operations to the graph before calling run().\n"
     ]
    }
   ],
   "source": [
    "# delete the current graph\n",
    "tf.reset_default_graph()\n",
    "try:\n",
    "    with tf.Session() as sess:\n",
    "        # restore the saved vairable\n",
    "        saver.restore(sess, './saved_variable')\n",
    "        # print the loaded variable\n",
    "        a_out, b_out = sess.run([a, b])\n",
    "        print('a = ', a_out)\n",
    "        print('b = ', b_out)\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the graph in two ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Define the graph from scratch and then run the session:\n",
    "This way is simple if you have your graph. So, what you can  do is to create the graph and then restore your variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_variable\n",
      "a =  [3 3]\n",
      "b =  [5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# delete the current graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# create a new graph\n",
    "# create variables a and b\n",
    "a = tf.get_variable(\"A\", initializer=tf.constant(3, shape=[2]))\n",
    "b = tf.get_variable(\"B\", initializer=tf.constant(5, shape=[3]))\n",
    "\n",
    "# initialize all of the variables\n",
    "init_op = tf.global_variables_initializer()# create the graph\n",
    "\n",
    "# create saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# run the session\n",
    "with tf.Session() as sess:\n",
    "    # restore the saved vairable\n",
    "    saver.restore(sess, './saved_variable')\n",
    "    # print the loaded variable\n",
    "    a_out, b_out = sess.run([a, b])\n",
    "    print('a = ', a_out)\n",
    "    print('b = ', b_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we do not know the graph and we are using someone else's pre-trained model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Restore the graph from `.meta` file.\n",
    "\n",
    "When we save the variables, it creates a `.meta` file. This file contains the graph structure. Therefore, we can import the meta graph using `tf.train.import_meta_graph()` and restore the values of the graph. Let's import the graph and see all tensors in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Const\n",
      "A\n",
      "A/Assign\n",
      "A/read\n",
      "Const_1\n",
      "B\n",
      "B/Assign\n",
      "B/read\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/RestoreV2_1/tensor_names\n",
      "save/RestoreV2_1/shape_and_slices\n",
      "save/RestoreV2_1\n",
      "save/Assign_1\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "# delete the current graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# import the graph from the file\n",
    "imported_graph = tf.train.import_meta_graph('saved_variable.meta')\n",
    "\n",
    "# list all the tensors in the graph\n",
    "for tensor in tf.get_default_graph().get_operations():\n",
    "    print (tensor.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you recall from section 1.1, we defined the python names with __lower__case letters and in TensorFlow names with __UPPER__case letters. You can see that what we have here are the __UPPER__case letter variables. It means that `tf.train.Saver()` saves the variables with the TensorFlow name. Now that we have the imported graph, and we know that we are interested in `A` and `B` tensors, we can restore the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_variable\n",
      "a =  [3 3]\n",
      "b =  [5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# run the session\n",
    "with tf.Session() as sess:\n",
    "    # restore the saved vairable\n",
    "    imported_graph.restore(sess, './saved_variable')\n",
    "    # print the loaded variable\n",
    "    a_out, b_out = sess.run(['A:0','B:0'])\n",
    "    print('a = ', a_out)\n",
    "    print('b = ', b_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important Note:__ Notice that in `sess.run()` we provided  the TensorFlow name of the tensors `'A:0'` and `'B:0'` instead of `a` and `b`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save and Restore Variables in Network:\n",
    "Comming soon ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
